# ==============================================================================
# å¤§æ¨¡åž‹AIå¼€å‘çŽ¯å¢ƒæ¨¡æ¿
# é€‚ç”¨äºŽï¼šLLMå¼€å‘ã€AIå¯¹è¯ç³»ç»Ÿã€å¤šæ¨¡æ€AIã€æ¨¡åž‹å¾®è°ƒã€RAGç³»ç»Ÿ
# Python ç‰ˆæœ¬ï¼šå‚æ•°åŒ–æ”¯æŒ 3.9-3.12
# ==============================================================================

# ðŸ’» ç³»ç»Ÿé…ç½®è¦æ±‚
# æœ€ä½Žé…ç½®ï¼š32GB RAM, 8GB å¯ç”¨ç£ç›˜ç©ºé—´, RTX 3060+ (12GB VRAM)
# æŽ¨èé…ç½®ï¼š64GB RAM, 20GB å¯ç”¨ç£ç›˜ç©ºé—´, RTX 4090 (24GB VRAM)
# é«˜æ€§èƒ½é…ç½®ï¼š128GB+ RAM, 50GB+ å¯ç”¨ç£ç›˜ç©ºé—´, A100/H100 (80GB VRAM)
# åŒ…å¤§å°ä¼°ç®—ï¼š~6.5GB (å®Œæ•´çš„ä¼ä¸šçº§LLMå¼€å‘å·¥å…·é“¾)
# æ”¯æŒç³»ç»Ÿï¼šWindows 11+, macOS 12+, Linux (Ubuntu 20.04+)
# å®‰è£…æ—¶é—´ï¼š30-60åˆ†é’Ÿ (å–å†³äºŽç½‘ç»œé€Ÿåº¦å’ŒGPUé©±åŠ¨)
# GPUè¦æ±‚ï¼šNVIDIA GPU (CUDA 11.8+) å¼ºçƒˆå»ºè®®
# ç‰¹æ®Šè¯´æ˜Žï¼šå¤§æ¨¡åž‹è®­ç»ƒå’ŒæŽ¨ç†å¯¹æ˜¾å­˜è¦æ±‚æžé«˜ï¼Œå»ºè®®24GB+ VRAM

name: ai-llm{{ '-' + suffix if suffix else '' }}

channels:
  - conda-forge
  - pytorch
  - nvidia
  - defaults

dependencies:
  # -----------------------------------------------------------------------------
  # æ ¸å¿ƒ Python çŽ¯å¢ƒ
  # -----------------------------------------------------------------------------
  - python={{ python_version }}.*           # Python è§£é‡Šå™¨
  - pip                                      # Python åŒ…ç®¡ç†å™¨

  # -----------------------------------------------------------------------------
  # æ·±åº¦å­¦ä¹ æ¡†æž¶åŸºç¡€
  # -----------------------------------------------------------------------------
  - pytorch>=2.1,<3.0                       # PyTorch æ ¸å¿ƒæ¡†æž¶
  - torchvision>=0.16,<1.0                  # è®¡ç®—æœºè§†è§‰æ”¯æŒ
  - torchaudio>=2.1,<3.0                    # éŸ³é¢‘å¤„ç†æ”¯æŒ
  - pytorch-cuda=11.8                       # CUDA æ”¯æŒ (GPUåŠ é€Ÿ)

  # -----------------------------------------------------------------------------
  # Jupyter å¼€å‘çŽ¯å¢ƒ (AIå®žéªŒå¿…éœ€)
  # -----------------------------------------------------------------------------
  - jupyter>=1.0,<2.0                       # Jupyter æ ¸å¿ƒ
  - jupyterlab>=4.0,<5.0                   # çŽ°ä»£å¼€å‘ç•Œé¢
  - ipywidgets>=8.0,<9.0                   # äº¤äº’å¼ç»„ä»¶

  # -----------------------------------------------------------------------------
  # æ•°æ®å¤„ç†åŸºç¡€ (AIæ•°æ®é¢„å¤„ç†)
  # -----------------------------------------------------------------------------
  - numpy>=1.21,<2.0                       # æ•°å€¼è®¡ç®—åŸºç¡€
  - pandas>=1.5,<3.0                       # æ•°æ®å¤„ç†å’Œåˆ†æž
  - scipy>=1.9,<2.0                        # ç§‘å­¦è®¡ç®—åº“

  # -----------------------------------------------------------------------------
  # å¯è§†åŒ–å·¥å…· (è®­ç»ƒç›‘æŽ§å’Œç»“æžœå±•ç¤º)
  # -----------------------------------------------------------------------------
  - matplotlib>=3.5,<4.0                   # åŸºç¡€ç»˜å›¾
  - seaborn>=0.11,<1.0                     # ç»Ÿè®¡å¯è§†åŒ–
  - plotly>=5.10,<6.0                      # äº¤äº’å¼å¯è§†åŒ–

  # -----------------------------------------------------------------------------
  # ç³»ç»Ÿç›‘æŽ§å’Œæ€§èƒ½å·¥å…·
  # -----------------------------------------------------------------------------
  - psutil>=5.9,<6.0                       # ç³»ç»Ÿèµ„æºç›‘æŽ§
  - tqdm>=4.64,<5.0                        # è¿›åº¦æ¡æ˜¾ç¤º

  # -----------------------------------------------------------------------------
  # åŸºç¡€å¼€å‘å·¥å…·
  # -----------------------------------------------------------------------------
  - black>=23.0,<25.0                      # ä»£ç æ ¼å¼åŒ–å·¥å…·
  - pytest>=7.2,<9.0                      # æµ‹è¯•æ¡†æž¶
  - ipython>=8.10,<9.0                    # å¢žå¼ºçš„äº¤äº’å¼ Python shell

  # -----------------------------------------------------------------------------
  # pip ä¾èµ– (LLM ä¸“ç”¨å·¥å…·ç”Ÿæ€)
  # -----------------------------------------------------------------------------
  - pip:
    # =========================================================================
    # ðŸ¤– Transformer å’Œ LLM æ ¸å¿ƒç”Ÿæ€
    # =========================================================================
    - transformers>=4.35,<5.0               # HuggingFace Transformers æ ¸å¿ƒåº“
    - tokenizers>=0.15,<1.0                 # å¿«é€Ÿ tokenization
    - datasets>=2.15,<3.0                   # æ•°æ®é›†å¤„ç†å’ŒåŠ è½½
    - evaluate>=0.4,<1.0                    # æ¨¡åž‹è¯„ä¼°å·¥å…·

    # =========================================================================
    # âš¡ å¤§æ¨¡åž‹è®­ç»ƒä¼˜åŒ–å’ŒåŠ é€Ÿ
    # =========================================================================
    - accelerate>=0.25,<1.0                 # åˆ†å¸ƒå¼è®­ç»ƒå’ŒæŽ¨ç†åŠ é€Ÿ
    - deepspeed>=0.12,<1.0                  # å¤§æ¨¡åž‹è®­ç»ƒå†…å­˜ä¼˜åŒ–
    - bitsandbytes>=0.41,<1.0               # æ¨¡åž‹é‡åŒ–å’Œä¼˜åŒ–

    # =========================================================================
    # ðŸŽ¯ å‚æ•°é«˜æ•ˆå¾®è°ƒ (PEFT)
    # =========================================================================
    - peft>=0.7,<1.0                        # LoRA, AdaLoRA ç­‰å¾®è°ƒæ–¹æ³•
    - trl>=0.7,<1.0                         # å¼ºåŒ–å­¦ä¹ å¾®è°ƒ (RLHF/DPO)

    # =========================================================================
    # ðŸ“Š å®žéªŒç®¡ç†å’Œç›‘æŽ§
    # =========================================================================
    - wandb>=0.16,<1.0                      # å®žéªŒè·Ÿè¸ªå’Œå¯è§†åŒ–
    - mlflow>=2.8,<3.0                      # æ¨¡åž‹ç”Ÿå‘½å‘¨æœŸç®¡ç†
    - tensorboard>=2.14,<3.0                # è®­ç»ƒå¯è§†åŒ–
    - gpustat>=1.1,<2.0                     # GPU ä½¿ç”¨ç›‘æŽ§

    # =========================================================================
    # ðŸŒ API æœåŠ¡å’Œéƒ¨ç½²
    # =========================================================================
    - fastapi>=0.104,<1.0                   # é«˜æ€§èƒ½ API æ¡†æž¶
    - uvicorn[standard]>=0.24,<1.0          # ASGI æœåŠ¡å™¨
    - gradio>=4.0,<5.0                      # å¿«é€ŸåŽŸåž‹å’Œæ¼”ç¤ºç•Œé¢
    - streamlit>=1.28,<2.0                  # Web åº”ç”¨æ¡†æž¶

    # =========================================================================
    # ðŸ” å‘é‡æ£€ç´¢å’Œ RAG æ”¯æŒ
    # =========================================================================
    - sentence-transformers>=2.2,<3.0       # æ–‡æœ¬å‘é‡åŒ–
    - faiss-cpu>=1.7,<2.0                   # é«˜æ•ˆå‘é‡ç›¸ä¼¼åº¦æœç´¢
    - chromadb>=0.4,<1.0                    # å‘é‡æ•°æ®åº“
    - langchain>=0.0.340,<1.0               # LLM åº”ç”¨å¼€å‘æ¡†æž¶

    # =========================================================================
    # ðŸ“ è‡ªç„¶è¯­è¨€å¤„ç†å¢žå¼ºå·¥å…·
    # =========================================================================
    - nltk>=3.8,<4.0                        # ä¼ ç»Ÿ NLP å·¥å…·åŒ…
    - spacy>=3.7,<4.0                       # çŽ°ä»£ NLP åº“
    - openai>=1.3,<2.0                      # OpenAI API å®¢æˆ·ç«¯

    # =========================================================================
    # ðŸŽ¨ å¤šæ¨¡æ€ AI æ”¯æŒ
    # =========================================================================
    - pillow>=9.0,<11.0                     # å›¾åƒå¤„ç†
    - librosa>=0.10,<1.0                    # éŸ³é¢‘å¤„ç†å’Œåˆ†æž
    - opencv-python>=4.8,<5.0               # è®¡ç®—æœºè§†è§‰

    # =========================================================================
    # ðŸ”§ é…ç½®ç®¡ç†å’Œå·¥å…·å¢žå¼º
    # =========================================================================
    - hydra-core>=1.3,<2.0                  # é…ç½®ç®¡ç†æ¡†æž¶
    - omegaconf>=2.3,<3.0                   # é…ç½®æ–‡ä»¶å¤„ç†
    - fire>=0.5,<1.0                        # å‘½ä»¤è¡Œå·¥å…·å¿«é€Ÿç”Ÿæˆ
    - python-multipart>=0.0.6,<1.0          # æ–‡ä»¶ä¸Šä¼ æ”¯æŒ (FastAPI)

    # =========================================================================
    # ðŸ“Š å¤§æ•°æ®å¤„ç†å¢žå¼º
    # =========================================================================
    - pyarrow>=12.0,<16.0                   # é«˜æ€§èƒ½æ•°æ®å¤„ç† (Parquet, Arrow)
    - polars>=0.20,<1.0                     # é«˜æ€§èƒ½æ•°æ®å¸§åº“
    - dask[complete]>=2023.12,<2025.0       # åˆ†å¸ƒå¼è®¡ç®—æ¡†æž¶

    # =========================================================================
    # ðŸŒ äº‘æœåŠ¡å’Œå­˜å‚¨é›†æˆ
    # =========================================================================
    - boto3>=1.28,<2.0                      # AWSæœåŠ¡é›†æˆ
    - azure-storage-blob>=12.19,<13.0       # Azure Blobå­˜å‚¨
    - google-cloud-storage>=2.10,<3.0       # Google Cloudå­˜å‚¨

    # =========================================================================
    # ðŸ“Š è¯„ä¼°å’ŒåŸºå‡†æµ‹è¯•
    # =========================================================================
    - lm-eval>=0.4,<1.0                     # å¤§æ¨¡åž‹è¯„ä¼°æ¡†æž¶
    - deepeval>=0.21,<1.0                   # LLMåº”ç”¨è¯„ä¼°å·¥å…·
    - ragas>=0.1,<1.0                       # RAGç³»ç»Ÿè¯„ä¼°å·¥å…·

    # =========================================================================
    # ðŸ”§ å®žç”¨å·¥å…·å’Œæ•°æ®å¤„ç†
    # =========================================================================
    - requests>=2.28,<3.0                   # HTTP è¯·æ±‚
    - beautifulsoup4>=4.11,<5.0             # ç½‘é¡µæ•°æ®è§£æž
    - PyYAML>=6.0,<7.0                      # YAML é…ç½®æ–‡ä»¶å¤„ç†
    - rich>=13.0,<14.0                      # ç¾ŽåŒ–ç»ˆç«¯è¾“å‡º
    - click>=8.0,<9.0                       # å‘½ä»¤è¡Œå·¥å…·å¼€å‘

    # =========================================================================
    # ðŸš€ é«˜æ€§èƒ½æŽ¨ç†å’ŒæœåŠ¡å¼•æ“Ž
    # =========================================================================
    - vllm>=0.7,<1.0                        # é«˜æ€§èƒ½LLMæŽ¨ç†å’ŒæœåŠ¡å¼•æ“Ž
    - optimum>=1.14,<2.0                    # æ¨¡åž‹ä¼˜åŒ–å·¥å…· (ONNX, OpenVINO)
    - onnx>=1.15,<2.0                       # å¼€æ”¾ç¥žç»ç½‘ç»œäº¤æ¢æ ¼å¼
    - safetensors>=0.4,<1.0                 # å®‰å…¨çš„å¼ é‡åºåˆ—åŒ–

    # =========================================================================
    # ðŸŽ›ï¸ é«˜çº§é‡åŒ–å’ŒåŽ‹ç¼©
    # =========================================================================
    - auto-gptq>=0.5,<1.0                   # GPTQé‡åŒ–ç®—æ³• (æƒé‡é‡åŒ–)
    - autoawq>=0.1.8,<1.0                   # AWQé‡åŒ–ç®—æ³• (æ¿€æ´»æ„ŸçŸ¥é‡åŒ–)
    - llm-compressor>=0.1,<1.0              # ç»Ÿä¸€æ¨¡åž‹åŽ‹ç¼©åº“ (vLLMåŽŸç”Ÿæ”¯æŒ)

    # =========================================================================
    # ðŸŽ¤ å¤šæ¨¡æ€AIå¢žå¼º (è¯­éŸ³å’Œè§†è§‰)
    # =========================================================================
    - openai-whisper>=20231117              # OpenAIè¯­éŸ³è¯†åˆ«æ¨¡åž‹
    - diffusers>=0.24,<1.0                  # æ‰©æ•£æ¨¡åž‹åº“ (å›¾åƒç”Ÿæˆ)
    - timm>=0.9,<1.0                        # å›¾åƒæ¨¡åž‹åº“

# ==============================================================================
# çŽ¯å¢ƒè¯´æ˜Ž
# ==============================================================================
# 
# ðŸŽ¯ é€‚ç”¨åœºæ™¯ï¼š
#   - å¤§è¯­è¨€æ¨¡åž‹ (LLM) å¼€å‘å’Œå¾®è°ƒ
#   - AI å¯¹è¯ç³»ç»Ÿå’Œæ™ºèƒ½åŠ©æ‰‹å¼€å‘
#   - RAG (æ£€ç´¢å¢žå¼ºç”Ÿæˆ) ç³»ç»Ÿæž„å»º
#   - å¤šæ¨¡æ€ AI åº”ç”¨ (æ–‡æœ¬+å›¾åƒ+éŸ³é¢‘)
#   - æ¨¡åž‹é‡åŒ–å’Œä¼˜åŒ–éƒ¨ç½²
#   - AI äº§å“åŽŸåž‹å¼€å‘å’Œæ¼”ç¤º
#
# ðŸš€ æ ¸å¿ƒèƒ½åŠ›ï¼š
#   - âœ… å®Œæ•´çš„ LLM å¼€å‘å·¥å…·é“¾ (transformers + datasets + tokenizers)
#   - âœ… é«˜æ•ˆæ¨¡åž‹è®­ç»ƒ (accelerate + deepspeed + åˆ†å¸ƒå¼)
#   - âœ… é«˜æ€§èƒ½æŽ¨ç†æœåŠ¡ (vLLM + optimized kernels)
#   - âœ… å‚æ•°é«˜æ•ˆå¾®è°ƒ (LoRA + QLoRA + RLHF)
#   - âœ… æ¨¡åž‹é‡åŒ–å’Œä¼˜åŒ– (GPTQ + AWQ + bitsandbytes)
#   - âœ… å‘é‡æ£€ç´¢å’Œ RAG (sentence-transformers + faiss + chromadb)
#   - âœ… API æœåŠ¡éƒ¨ç½² (fastapi + gradio + streamlit)
#   - âœ… å®žéªŒç®¡ç†å’Œç›‘æŽ§ (wandb + mlflow + tensorboard)
#   - âœ… å¤šæ¨¡æ€æ”¯æŒ (å›¾åƒ + éŸ³é¢‘ + è¯­éŸ³å¤„ç†)
#   - âœ… æ•°æ®å¤„ç†å’Œå¯è§†åŒ– (pandas + matplotlib)
#
# ðŸ”§ å…¸åž‹å·¥ä½œæµï¼š
#   conda activate my-llm-project
#   jupyter lab                             # å¯åŠ¨å¼€å‘çŽ¯å¢ƒ
#   # 1. æ•°æ®å‡†å¤‡å’Œé¢„å¤„ç† (datasets + tokenizers)
#   # 2. æ¨¡åž‹åŠ è½½å’Œé…ç½® (transformers + é¢„è®­ç»ƒæ¨¡åž‹)
#   # 3. å¾®è°ƒè®­ç»ƒ (accelerate + deepspeed + wandbç›‘æŽ§)
#   # 4. æ¨¡åž‹è¯„ä¼°å’Œä¼˜åŒ– (evaluate + é‡åŒ– + lm-eval)
#   # 5. é«˜æ€§èƒ½éƒ¨ç½² (vLLM + fastapi + gradio)
#   # 6. RAG ç³»ç»Ÿæž„å»º (langchain + å‘é‡æ•°æ®åº“)
#
# ðŸŽ® å¿«é€Ÿå¼€å§‹ç¤ºä¾‹ï¼š
#   # åŠ è½½é¢„è®­ç»ƒæ¨¡åž‹
#   from transformers import AutoTokenizer, AutoModelForCausalLM
#   model = AutoModelForCausalLM.from_pretrained("meta-llama/Llama-2-7b-hf")
#   
#   # LoRA å¾®è°ƒ
#   from peft import get_peft_model, LoraConfig
#   peft_config = LoraConfig(task_type="CAUSAL_LM", r=16, lora_alpha=32)
#   model = get_peft_model(model, peft_config)
#   
#   # åˆ†å¸ƒå¼è®­ç»ƒ
#   from accelerate import Accelerator
#   accelerator = Accelerator()
#   model, optimizer, dataloader = accelerator.prepare(model, optimizer, dataloader)
#   
#   # é«˜æ€§èƒ½æŽ¨ç†éƒ¨ç½²
#   import vllm
#   llm = vllm.LLM(model="meta-llama/Llama-2-7b-hf", quantization="gptq")
#   outputs = llm.generate(["Tell me a joke"], sampling_params=vllm.SamplingParams())
#   
#   # éƒ¨ç½² API æœåŠ¡
#   import gradio as gr
#   demo = gr.ChatInterface(fn=chat_function)
#   demo.launch()
#
# ðŸ“ˆ ä¸Žå…¶ä»–æ¨¡æ¿çš„å…³ç³»ï¼š
#   - åŸºäºŽ deeplearning-pytorch.yml çš„æ ¸å¿ƒèƒ½åŠ›
#   - ä¸“é—¨ä¼˜åŒ–ç”¨äºŽå¤§æ¨¡åž‹å’Œç”Ÿæˆå¼ AI
#   - å¯ä¸Ž web-fastapi.yml ç»“åˆç”¨äºŽç”Ÿäº§éƒ¨ç½²
#   - åŒ…å«å®Œæ•´çš„æ•°æ®ç§‘å­¦åŸºç¡€å·¥å…·
#
# ðŸ’¾ å­˜å‚¨éœ€æ±‚ï¼š
#   - çŽ¯å¢ƒæœ¬èº«: ~6.5GB (å¢žåŠ äº†é«˜æ€§èƒ½æŽ¨ç†å’Œé‡åŒ–å·¥å…·)
#   - é¢„è®­ç»ƒæ¨¡åž‹ (7B): ~15GB
#   - é¢„è®­ç»ƒæ¨¡åž‹ (13B): ~30GB  
#   - é¢„è®­ç»ƒæ¨¡åž‹ (70B): ~150GB
#   - å»ºè®®é¢„ç•™: 100GB+ (ç”¨äºŽæ¨¡åž‹å’Œæ•°æ®)
#
# ðŸ”§ ç¡¬ä»¶å»ºè®®ï¼š
#   # å­¦ä¹ å’Œå°æ¨¡åž‹å¾®è°ƒ (7Bä»¥ä¸‹)
#   RTX 3060 (12GB) + 32GB RAM
#   
#   # ä¸­ç­‰æ¨¡åž‹å¼€å‘ (7B-13B)
#   RTX 4090 (24GB) + 64GB RAM
#   
#   # å¤§æ¨¡åž‹è®­ç»ƒ (70B+)
#   A100 (80GB) + 128GB+ RAM æˆ–å¤šå¡è®¾ç½®
#
# ðŸŒŸ ç‰¹è‰²åŠŸèƒ½ï¼š
#   - ðŸ¤– æ”¯æŒä¸»æµå¼€æºå¤§æ¨¡åž‹ (Llama, Qwen, ChatGLM, Baichuan, DeepSeek)
#   - âš¡ å†…å­˜é«˜æ•ˆè®­ç»ƒ (DeepSpeed ZeRO, Gradient Checkpointing, vLLMæŽ¨ç†)
#   - ðŸŽ¯ å‚æ•°é«˜æ•ˆå¾®è°ƒ (LoRA, QLoRA, AdaLoRA, IA3)
#   - ðŸ” ä¼ä¸šçº§ RAG ç³»ç»Ÿ (å‘é‡æ•°æ®åº“ + è¯­ä¹‰æ£€ç´¢)
#   - ðŸŒ ç”Ÿäº§å°±ç»ªéƒ¨ç½² (API + Webç•Œé¢ + æ€§èƒ½ç›‘æŽ§)
#   - ðŸŽ¨ å¤šæ¨¡æ€èƒ½åŠ› (æ–‡æœ¬+å›¾åƒ+éŸ³é¢‘å¤„ç†)
#
# ðŸ“š å­¦ä¹ èµ„æºï¼š
#   - Transformers æ–‡æ¡£: https://huggingface.co/docs/transformers
#   - DeepSpeed æ•™ç¨‹: https://www.deepspeed.ai/tutorials/
#   - LangChain æŒ‡å—: https://python.langchain.com/docs/
#   - PEFT æ•™ç¨‹: https://huggingface.co/docs/peft